---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: velero
  namespace: velero
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://vmware-tanzu.github.io/helm-charts
      chart: velero
      version: 4.4.1
      sourceRef:
        kind: HelmRepository
        name: vmware-tanzu-charts
        namespace: flux-system
  maxHistory: 2
  install:
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 30
  uninstall:
    keepHistory: false
  values:
    image:
      repository: velero/velero
      tag: v1.13.0
    configuration:
      snapshotVolumes: true
      extraEnvVars:
        TZ: "Europe/Paris"
      backupStorageLocation:
        - name: default
          bucket: velero
          provider: aws
          default: true
          config:
            region: us-east-1
            s3ForcePathStyle: true
            s3Url: http://minio.default.svc.cluster.local:9000
            publicUrl: https://s3.${CLOUDED_DOMAIN}
      volumeSnapshotLocation:
        - name: default
          bucket: restic
          provider: aws
          default: true
          config:
            region: us-east-1
            s3ForcePathStyle: true
            s3Url: http://minio.default.svc.cluster.local:9000
            publicUrl: https://s3.${CLOUDED_DOMAIN}

      resticTimeout: 4h
      defaultVolumesToFsBackup: true
      includeClusterResources: true

    initContainers:
      - name: velero-plugin-for-aws
        image: velero/velero-plugin-for-aws:v1.9.0
        imagePullPolicy: IfNotPresent
        volumeMounts:
          - mountPath: /target
            name: plugins

    credentials:
      useSecret: true
      existingSecret: velero-secret

    schedules:
#      daily-backup:
#        # At 6:00am in the morning every day
#        schedule: "0 6 * * *"
#        template:
#          ttl: "168h"
      weekly-backup:
        # At the end of the week on a Sunday morning, at 6:00am
        schedule: "0 6 * * 0"
        template:
          ttl: "672h"

    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
    backupsEnabled: true
    snapshotsEnabled: true
    upgradeCRDs: false
    cleanUpCRDs: false

    kubectl:
      image:
        repository: ghcr.io/onedr0p/kubernetes-kubectl
        tag: 1.29.2

    deployNodeAgent: true

    nodeAgent:
      podVolumePath: /var/lib/kubelet/pods
      privileged: false
      tolerations:
        - key: "node-role.kubernetes.io/master"
          operator: "Exists"
      resources:
        requests:
          memory: 200Mi
          cpu: 15m
        limits:
          memory: 3000Mi

    resources:
      requests:
        memory: 300Mi
        cpu: 25m
      limits:
        memory: 1500Mi
